<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="boosting">Boosting</h1> <p>Boosting is also a general approach that can be applied to many statistical methods. Unlike bagging, boosting use the same dataset. Boosting works on top of weak learners as in very simple algorithms or simple version of a powerful algorithm. For example, a decision tree with 1 split allowed is a weak learner. Output of that tree will be closer to random guessing. Boosting trains the same weak learner multiple times and after each training iterations, updates the dataset.</p> <h2 id="adaboost">AdaBoost</h2> <p>It is a binary classifier where (Y \in {-1, +1}). The algorithm begins with setting up weights (D_i = \frac{1}{N}) for each observation (X_i) where (i=1…N). Suppose we train (T) models, then output from the (t_{th}) model will be (G_t(x_i)). Before the training of (t_{th}) model, we update (X) as (X_i = X_i \times D_i). As we can see, it is element wise operation. This considers as “punishing” the training samples which were misclassified in the previous model. Now that we have punished and trained, we will calculate the error, (err_t)</p> <p>[ \frac{ \sum_{i=1}^{N} D_i \times I(y_i \ne G_t(x_i)) }{\sum_{i=1}^{N} D_i} ]</p> <p>(I(condition)) returns 1 or 0 if the condition is true or false respectively. Now we will have multiple models at our hand and when finally combining their results, we should give more priorities to the more accurate models. This is achieved by calculating, (\alpha_t = \log\left( \frac{1-err_t}{err_t} \right)). Also, we haven’t updated the weights (D_i). They should be updated based on their performance on (t_{th}) tree.</p> <p>[ D_i = D_i \times \exp(\alpha_t \times I(y_i \ne G_t(X_i))) ]</p> <p>using (I(y_i \ne G_t(X_i))) makes sure that we don’t update samples that have been correctly classified. Finally after training of (T) models, we combine their result using majority vote.</p> <p>[ G(x) = sign\left(\sum_{t=1}^{T} \alpha_t \times G_t(x)\right) ]</p> <p>(sign(x)) returns -1 if (x) is negative, 1 if (x) is positive, and 0 if (x) is zero.</p> <h2 id="implementation">Implementation</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AdaBoost</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="n">self</span><span class="p">.</span><span class="n">modelContainer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">modelAlpha</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">nSamples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">full</span><span class="p">(</span><span class="n">fill_value</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">nSamples</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">nSamples</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">modelContainer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">modelAlpha</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">T</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">estimator_weights_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">estimator_errors_</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">D</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">error_indices</span> <span class="o">=</span> <span class="n">y</span> <span class="o">!=</span> <span class="n">predictions</span>
            <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">D</span><span class="p">[</span><span class="n">error_indices</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">D</span><span class="p">)</span>
            
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">err</span><span class="p">)</span> <span class="o">/</span> <span class="n">err</span><span class="p">)</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">D</span><span class="p">[</span><span class="n">error_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">D</span><span class="p">[</span><span class="n">error_indices</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">modelContainer</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">modelAlpha</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>
<span class="c1">#             storing meta information
</span>            <span class="n">self</span><span class="p">.</span><span class="n">estimator_weights_</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">estimator_errors_</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">nSamples</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">nSamples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">T</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">T</span><span class="p">):</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">modelContainer</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
            <span class="n">Y</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">modelAlpha</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sign</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
    
    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
        
</code></pre></div></div> <h3 id="trying-out-the-model">Trying out the model</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([.</span><span class="mi">1</span><span class="p">,.</span><span class="mi">2</span><span class="p">,.</span><span class="mi">4</span><span class="p">,.</span><span class="mi">8</span><span class="p">,</span> <span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="p">.</span><span class="mi">05</span><span class="p">,.</span><span class="mi">08</span><span class="p">,.</span><span class="mi">12</span><span class="p">,.</span><span class="mi">33</span><span class="p">,.</span><span class="mi">55</span><span class="p">,.</span><span class="mi">66</span><span class="p">,.</span><span class="mi">77</span><span class="p">,.</span><span class="mi">88</span><span class="p">,.</span><span class="mi">2</span><span class="p">,.</span><span class="mi">3</span><span class="p">,.</span><span class="mi">4</span><span class="p">,.</span><span class="mi">5</span><span class="p">,.</span><span class="mi">6</span><span class="p">,.</span><span class="mi">25</span><span class="p">,.</span><span class="mi">3</span><span class="p">,.</span><span class="mi">5</span><span class="p">,.</span><span class="mi">7</span><span class="p">,.</span><span class="mi">6</span><span class="p">])</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([.</span><span class="mi">2</span><span class="p">,.</span><span class="mi">65</span><span class="p">,.</span><span class="mi">7</span><span class="p">,.</span><span class="mi">6</span><span class="p">,</span> <span class="p">.</span><span class="mi">3</span><span class="p">,.</span><span class="mi">1</span><span class="p">,.</span><span class="mi">4</span><span class="p">,.</span><span class="mi">66</span><span class="p">,.</span><span class="mi">77</span><span class="p">,.</span><span class="mi">65</span><span class="p">,.</span><span class="mi">68</span><span class="p">,.</span><span class="mi">55</span><span class="p">,.</span><span class="mi">44</span><span class="p">,.</span><span class="mi">1</span><span class="p">,.</span><span class="mi">3</span><span class="p">,.</span><span class="mi">4</span><span class="p">,.</span><span class="mi">3</span><span class="p">,.</span><span class="mi">15</span><span class="p">,.</span><span class="mi">15</span><span class="p">,.</span><span class="mi">5</span><span class="p">,.</span><span class="mi">55</span><span class="p">,.</span><span class="mi">2</span><span class="p">,.</span><span class="mi">4</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">)).</span><span class="n">T</span>

<span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">==-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</code></pre></div></div> <p>sklearn’s</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">boost</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span> <span class="n">base_estimator</span> <span class="o">=</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> 
                            <span class="n">algorithm</span> <span class="o">=</span> <span class="sh">'</span><span class="s">SAMME</span><span class="sh">'</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">boost</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">boost</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8695652173913043
</code></pre></div></div> <p>ours</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ab</span> <span class="o">=</span> <span class="nc">AdaBoost</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ab</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ab</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8695652173913043
</code></pre></div></div> <p>nice!</p> <h1 id="references">References</h1> <ol> <li>Freund, Yoav, and Robert E. Schapire. “A desicion-theoretic generalization of on-line learning and an application to boosting.” European conference on computational learning theory. Springer, Berlin, Heidelberg, 1995.</li> <li>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. The elements of statistical learning: data mining, inference, and prediction. Springer Science &amp; Business Media, 2009.</li> <li>James, Gareth, et al. An introduction to statistical learning. Vol. 112. New York: springer, 2013.</li> </ol> </body></html>