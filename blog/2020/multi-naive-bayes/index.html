<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Multinomial naive bayes is the naive Bayes algorithm for multinomially distributed data. For a brief and intuitive explanation of Bayes theorem, read this kernel of mine: <a href="https://www.kaggle.com/riyadhrazzaq/gaussian-naive-bayes-classifier" rel="external nofollow noopener" target="_blank">Gaussian Naive Bayes Classifier from Scratch</a>. Everything is similar to Gaussian NB except the \(P(x_i \mid y)\). The new equation is, \(P(x_i \mid y) = \frac{N_{yi} + \alpha}{N_y + \alpha n} \label{eq1}\tag{1}\) Here,</p> <ul> <li>\(\alpha\) is the smoothing parameter,</li> <li>\(N_{yi}\) is the count of feature \(x_i\) in class y.</li> <li>\(N_y\) is the total count of all features in class y</li> <li>\(n\) is the total number of features</li> </ul> <h1 id="multinomial-naive-bayes">Multinomial Naive Bayes</h1> <p>You can look up in detail about multinomial distribution and you should. I will only put a short description of how a multinomial naive bayes classifier considers data.</p> <h2 id="multinomial-data">Multinomial Data</h2> <table> <thead> <tr> <th>\(X_1\)</th> <th>\(X_2\)</th> <th>\(X_3\)</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>0</td> <td>4</td> </tr> <tr> <td>4</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <p>In the table above containing 2 sample of 3 features, we observe that feature \(X_1\) has values 1 and 4, and so on. That is the common view of the data. And when other a general model accepts this data, it considers each number as value. For example, \(X_{1,2}=3\). But in case of reading a multinomial data, \(X_{1,2}\) says how many of feature \(X_{2}\) is in sample 1. Meaning \(X_{1,2}\) is not value of the feature, instead it is the count of the feature. Let’s consider a text corpus. Each sentence is made up of different words \(w_i\) and each of those \(w_i\) belongs to the vocabulary, \(V\). If \(V\) contains 8 words, \(w_1,w_2,...,w_8\) and if a sentence is: w1 w2 w2 w6 w3 w2 w8, the representation of that sentence will be-</p> <table> <thead> <tr> <th>\(w_1\)</th> <th>\(w_2\)</th> <th>\(w_3\)</th> <th>\(w_4\)</th> <th>\(w_5\)</th> <th>\(w_6\)</th> <th>\(w_7\)</th> <th>\(w_8\)</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>3</td> <td>1</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>1</td> </tr> </tbody> </table> <p>After inserting some other random sentences, the dataset is-</p> <table> <thead> <tr> <th>\(w_1\)</th> <th>\(w_2\)</th> <th>\(w_3\)</th> <th>\(w_4\)</th> <th>\(w_5\)</th> <th>\(w_6\)</th> <th>\(w_7\)</th> <th>\(w_8\)</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>3</td> <td>1</td> <td>0</td> <td>0</td> <td>1</td> <td>0</td> <td>1</td> </tr> <tr> <td>1</td> <td>0</td> <td>0</td> <td>0</td> <td>1</td> <td>1</td> <td>1</td> <td>3</td> </tr> <tr> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>0</td> <td>2</td> <td>1</td> <td>2</td> </tr> </tbody> </table> <p>By the way, I haven’t put them in a class. Randomly taking, \(y\) = [1,0,1]. Now, comparing with the equation of above,</p> <ul> <li>\(N_{yi}\) is the count of feature \(w_i\) in each unique class of y. For example, for \(y=1\), \(N_{y,1}=1, N_{y,6}=3\)</li> <li>\(N_y\) is the total count of all features in each unique class of y. For example, for \(y=1\), \(N_y=12\)</li> <li>\(n=8\) is the total number of features</li> <li>\(\alpha\) is known as smoothing parameter. It is needed for zero probability problem which is explained in resource [1]</li> </ul> <p>To calculate likelyhoods for a test sentence, all we need is \(P(w_i \mid y)\) which will be used to calculate \(P(X \mid y)\) from training data. But \(P(w_i \mid y)\) is the probability of feature \(w_i\) appearing under class y once. If our test sentence has any feature \(w_i\) n times, we will need to include \(P(w_i \mid y)\) in \(P(X \mid y)\) n times too. So, final equation for \(P(X_i \mid y)\) will be-</p> \[P(X_i \mid y) = P(w_1 \mid y)^{X_{i,1}} \times P(w_2 \mid y)^{X_{i,2}} \times ... \times P(w_n \mid y)^{X_{i,n}}\] <p>Resources:</p> <ol> <li>https://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn07-notes-nup.pdf</li> <li>https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes</li> </ol> <h3 id="some-libraries-and-test-data">Some libraries and test data</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> 
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test data
</span><span class="n">tmpX1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">int</span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="nf">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="sh">"</span><span class="s">2   0   0   0   1   2   3   1  0   0   1   0   2   1   0   0  0   1   0   1   0   2   1   0  1   0   0   2   0   1   0   1  2   0   0   0   1   0   1   3  0   0   1   2   0   0   2   1</span><span class="sh">"</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">  </span><span class="sh">"</span><span class="p">)])</span>
<span class="n">tmpX2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">int</span><span class="p">(</span><span class="n">i</span><span class="p">.</span><span class="nf">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="sh">"</span><span class="s">0   1   1   0   0   0   1   0  1   2   0   1   0   0   1   1  0   1   1   0   0   2   0   0  0   0   0   0   0   0   0   0  0   0   1   0   1   0   1   0</span><span class="sh">"</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">  </span><span class="sh">"</span><span class="p">)])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">tmpX1</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">tmpX2</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X and Y shapes</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X and Y shapes
 (11, 8) (11,)
</code></pre></div></div> <h1 id="class-multinb">Class MultiNB</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiNB</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
    
    <span class="k">def</span> <span class="nf">_prior</span><span class="p">(</span><span class="n">self</span><span class="p">):</span> <span class="c1"># CHECKED
</span>        <span class="sh">"""</span><span class="s">
        Calculates prior for each unique class in y. P(y)
        </span><span class="sh">"""</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">))</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span><span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">classes_</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">n_samples</span>
        <span class="k">return</span> <span class="n">P</span>
            
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span> <span class="c1"># CHECKED, matches with sklearn
</span>        <span class="sh">"""</span><span class="s">
        Calculates the following things- 
            class_priors_ is list of priors for each y.
            N_yi: 2D array. Contains for each class in y, the number of time each feature i appears under y.
            N_y: 1D array. Contains for each class in y, the number of all features appear under y.
            
        params
        ------
        X: 2D array. shape(n_samples, n_features)
            Multinomial data
        y: 1D array. shape(n_samples,). Labels must be encoded to integers.
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">self</span><span class="p">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">classes_</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">class_priors_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_prior</span><span class="p">()</span>
        
        <span class="c1"># distinct values in each features
</span>        <span class="n">self</span><span class="p">.</span><span class="n">uniques</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">uniques</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span> <span class="n">tmp</span> <span class="p">)</span>
            
        <span class="n">self</span><span class="p">.</span><span class="n">N_yi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">))</span> <span class="c1"># feature count
</span>        <span class="n">self</span><span class="p">.</span><span class="n">N_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">))</span> <span class="c1"># total count 
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">classes_</span><span class="p">:</span> <span class="c1"># x axis
</span>            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argwhere</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">y</span><span class="o">==</span><span class="n">i</span><span class="p">).</span><span class="nf">flatten</span><span class="p">()</span>
            <span class="n">columnwise_sum</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">):</span> <span class="c1"># y axis
</span>                <span class="n">columnwise_sum</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">,</span><span class="n">j</span><span class="p">]))</span>
                
            <span class="n">self</span><span class="p">.</span><span class="n">N_yi</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">columnwise_sum</span> <span class="c1"># 2d
</span>            <span class="n">self</span><span class="p">.</span><span class="n">N_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">columnwise_sum</span><span class="p">)</span> <span class="c1"># 1d
</span>            
    <span class="k">def</span> <span class="nf">_theta</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Calculates theta_yi. aka P(xi | y) using eqn(1) in the notebook.
        
        params
        ------
        x_i: int. 
            feature x_i
            
        i: int.
            feature index. 
            
        h: int or string.
            a class in y
        
        returns
        -------
        theta_yi: P(xi | y)
        </span><span class="sh">"""</span>
        
        <span class="n">Nyi</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">N_yi</span><span class="p">[</span><span class="n">h</span><span class="p">,</span><span class="n">i</span><span class="p">]</span>
        <span class="n">Ny</span>  <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">N_y</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>
        
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">Nyi</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">alpha</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">Ny</span> <span class="o">+</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">)</span>
        
        <span class="nf">return  </span><span class="p">(</span><span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span><span class="p">)</span><span class="o">**</span><span class="n">x_i</span>
    
    <span class="k">def</span> <span class="nf">_likelyhood</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Calculates P(E|H) = P(E1|H) * P(E2|H) .. * P(En|H).
        
        params
        ------
        x: array. shape(n_features,)
            a row of data.
        h: int. 
            a class in y
        </span><span class="sh">"""</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">_theta</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">prod</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">self</span><span class="p">.</span><span class="n">predict_proba</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">samples</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">joint_likelyhood</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">))</span>
            
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">):</span>
                <span class="n">joint_likelyhood</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>  <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_priors_</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="nf">_likelyhood</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">h</span><span class="p">)</span> <span class="c1"># P(y) P(X|y) 
</span>                
            <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">joint_likelyhood</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes_</span><span class="p">):</span>
                <span class="n">numerator</span> <span class="o">=</span> <span class="n">joint_likelyhood</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>
                <span class="n">self</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span><span class="p">)</span>
            
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">classes_</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pipeline</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Sklearn Sanity Check
    </span><span class="sh">"""</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span><span class="sh">'</span><span class="s">Sklearn</span><span class="sh">'</span><span class="p">,</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="nc">MultinomialNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">sk_y</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature Count </span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">clf</span><span class="p">.</span><span class="n">feature_count_</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Class Log Prior </span><span class="sh">"</span><span class="p">,</span><span class="n">clf</span><span class="p">.</span><span class="n">class_log_prior_</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy </span><span class="sh">'</span><span class="p">,</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">sk_y</span><span class="p">),</span><span class="n">sk_y</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="nf">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span><span class="sh">'</span><span class="s">Custom</span><span class="sh">'</span><span class="p">,</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="nc">MultiNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">nb</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">nb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">me_score</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature Count</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span><span class="n">nb</span><span class="p">.</span><span class="n">N_yi</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Class Log Prior </span><span class="sh">"</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">nb</span><span class="p">.</span><span class="n">class_priors_</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy </span><span class="sh">'</span><span class="p">,</span><span class="n">me_score</span><span class="p">,</span><span class="n">yhat</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">nb</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">)</span> <span class="c1"># my predict proba is only for last test set
</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">pipeline</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-------------------- Sklearn --------------------
Feature Count 
 [[5. 1. 2. 5. 4. 6. 7. 6.]
 [1. 4. 3. 1. 1. 2. 3. 1.]]
Class Log Prior  [-0.6061358  -0.78845736]
Accuracy  0.8181818181818182 [0 0 0 0 0 0 1 1 1 0 0]
[[0.74940942 0.25059058]
 [0.52879735 0.47120265]
 [0.53711475 0.46288525]
 [0.69613326 0.30386674]
 [0.75239818 0.24760182]
 [0.62207341 0.37792659]
 [0.39213534 0.60786466]
 [0.45705923 0.54294077]
 [0.42055705 0.57944295]
 [0.54545455 0.45454545]
 [0.51099295 0.48900705]]
-------------------- Custom --------------------
Feature Count
 [[5. 1. 2. 5. 4. 6. 7. 6.]
 [1. 4. 3. 1. 1. 2. 3. 1.]]
Class Log Prior  [-0.6061358  -0.78845736]
Accuracy  0.8181818181818182 [0 0 0 0 0 0 1 1 1 0 0]
[[0.74940942 0.25059058]
 [0.52879735 0.47120265]
 [0.53711475 0.46288525]
 [0.69613326 0.30386674]
 [0.75239818 0.24760182]
 [0.62207341 0.37792659]
 [0.39213534 0.60786466]
 [0.45705923 0.54294077]
 [0.42055705 0.57944295]
 [0.54545455 0.45454545]
 [0.51099295 0.48900705]]
</code></pre></div></div> <h1 id="spam-classification">Spam Classification</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">import</span> <span class="n">string</span>
<span class="kn">from</span> <span class="n">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelBinarizer</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">../data/spam_uci.csv</span><span class="sh">"</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">iso8859_14</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <h2 id="simple-preprocessing">Simple Preprocessing</h2> <p>to cleanup punctuations and stopwords</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">clean_util</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">punc_rmv</span> <span class="o">=</span> <span class="p">[</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">]</span>
    <span class="n">punc_rmv</span> <span class="o">=</span> <span class="sh">""</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">punc_rmv</span><span class="p">)</span>
    <span class="n">stopword_rmv</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">punc_rmv</span><span class="p">.</span><span class="nf">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">w</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">)]</span>
    
    <span class="k">return</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">stopword_rmv</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">clean_util</span><span class="p">)</span>
</code></pre></div></div> <h1 id="vectorizing">Vectorizing</h1> <p>Conforming the texts to the multinomial format we have discussed in the beginning. Also, classes in y must be converted to integers as I forgot to account for strings in my implementation and too lazy to update •͡˘㇁•͡˘</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cv</span> <span class="o">=</span> <span class="nc">CountVectorizer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]).</span><span class="nf">toarray</span><span class="p">()</span>
<span class="n">lb</span> <span class="o">=</span> <span class="nc">LabelBinarizer</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">lb</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]).</span><span class="nf">ravel</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5572, 9381) (5572,)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train Test Split
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(4179, 9381) (1393, 9381) (4179,) (1393,)
</code></pre></div></div> <p>sklearn’s <code class="language-plaintext highlighter-rouge">MultinomialNB</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sk</span> <span class="o">=</span> <span class="nc">MultinomialNB</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">sk</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9755922469490309
</code></pre></div></div> <p>our <code class="language-plaintext highlighter-rouge">MultiNB</code> (⌐■_■)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="n">me</span> <span class="o">=</span> <span class="nc">MultiNB</span><span class="p">()</span>
<span class="n">me</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">me</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">yhat</span><span class="p">))</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9755922469490309
CPU times: user 1min 5s, sys: 0 ns, total: 1min 5s
Wall time: 1min 5s
</code></pre></div></div> <p>It takes a lot of time but does not matter as it is a reference implementation only ヽ(｀Д´)ﾉ</p> <p><strong>I wrote the scratch implementation for my learning, if you see any error or typo, please let me know.</strong></p> </body></html>